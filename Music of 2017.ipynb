{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xl = pd.ExcelFile(r'C:\\Users\\ashle\\OneDrive\\Documents\\Data Fun\\TSJ\\TSJ.xlsx')\n",
    "data = xl.parse('Data')\n",
    "data=data.drop(['Review','Length (MM:SS)', 'Min', 'Sec'], axis=1)\n",
    "data['ReleaseDate'] = pd.to_datetime(data['ReleaseDate'])\n",
    "data['Year'] = data['ReleaseDate'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Score = 5.7\n"
     ]
    }
   ],
   "source": [
    "print 'Average Score = ' + str(data[\"Score\"].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sort by Primary Genre\n",
      "                  count      mean       std  min   25%  50%   75%  max\n",
      "PrimaryGenre                                                          \n",
      "Pop                19.0  5.473684  1.611363  3.0  4.50  6.0  6.50  9.0\n",
      "Hip Hop            14.0  5.285714  2.233609  0.0  4.00  5.5  6.00  9.0\n",
      "Country             9.0  5.666667  1.581139  3.0  5.00  6.0  7.00  8.0\n",
      "Dance               7.0  5.571429  1.902379  4.0  4.00  5.0  6.50  9.0\n",
      "R&B                 6.0  6.666667  1.032796  5.0  6.25  7.0  7.00  8.0\n",
      "Alternative Rock    4.0  7.500000  1.290994  6.0  6.75  7.5  8.25  9.0\n",
      "House               3.0  5.333333  1.527525  4.0  4.50  5.0  6.00  7.0\n",
      "J-Pop               2.0  5.000000  0.000000  5.0  5.00  5.0  5.00  5.0\n",
      "Synthpop            2.0  5.500000  2.121320  4.0  4.75  5.5  6.25  7.0\n",
      "Grime               2.0  6.000000  0.000000  6.0  6.00  6.0  6.00  6.0\n",
      "Electropop          2.0  5.500000  2.121320  4.0  4.75  5.5  6.25  7.0\n",
      "Alternative         1.0  5.000000       NaN  5.0  5.00  5.0  5.00  5.0\n",
      "Folk                1.0  7.000000       NaN  7.0  7.00  7.0  7.00  7.0\n",
      "K-Pop               1.0  5.000000       NaN  5.0  5.00  5.0  5.00  5.0\n",
      "Latin Pop           1.0  4.000000       NaN  4.0  4.00  4.0  4.00  4.0\n",
      "Pop Folk            1.0  6.000000       NaN  6.0  6.00  6.0  6.00  6.0\n",
      "Bollywood           1.0  5.000000       NaN  5.0  5.00  5.0  5.00  5.0\n",
      "Rock                1.0  6.000000       NaN  6.0  6.00  6.0  6.00  6.0\n",
      "Salsa               1.0  6.000000       NaN  6.0  6.00  6.0  6.00  6.0\n",
      "Soul                1.0  9.000000       NaN  9.0  9.00  9.0  9.00  9.0\n",
      "Afrobeat            1.0  5.000000       NaN  5.0  5.00  5.0  5.00  5.0\n",
      "\n",
      "Sort by Secondary Genre\n",
      "                   count      mean       std  min   25%  50%   75%  max\n",
      "SecondaryGenre                                                         \n",
      " Pop                 7.0  5.857143  1.573592  4.0  4.50  6.0  7.00  8.0\n",
      " Trap                4.0  5.000000  0.816497  4.0  4.75  5.0  5.25  6.0\n",
      " Pop Rock            3.0  7.333333  1.527525  6.0  6.50  7.0  8.00  9.0\n",
      " Dance               3.0  5.333333  1.527525  4.0  4.50  5.0  6.00  7.0\n",
      " Grime               3.0  6.333333  2.516611  4.0  5.00  6.0  7.50  9.0\n",
      " Hip Hop             3.0  6.000000  0.000000  6.0  6.00  6.0  6.00  6.0\n",
      " Dancehall           2.0  6.500000  0.707107  6.0  6.25  6.5  6.75  7.0\n",
      " Synthpop            2.0  5.500000  2.121320  4.0  4.75  5.5  6.25  7.0\n",
      " Soul                2.0  5.500000  0.707107  5.0  5.25  5.5  5.75  6.0\n",
      "Indie                1.0  7.000000       NaN  7.0  7.00  7.0  7.00  7.0\n",
      "Dancehall            1.0  5.000000       NaN  5.0  5.00  5.0  5.00  5.0\n",
      " R&B                 1.0  9.000000       NaN  9.0  9.00  9.0  9.00  9.0\n",
      " Alternative         1.0  4.000000       NaN  4.0  4.00  4.0  4.00  4.0\n",
      " Pop Folk            1.0  3.000000       NaN  3.0  3.00  3.0  3.00  3.0\n",
      " Alternative Rock    1.0  6.000000       NaN  6.0  6.00  6.0  6.00  6.0\n",
      " Latin Trap          1.0  4.000000       NaN  4.0  4.00  4.0  4.00  4.0\n",
      " Indie               1.0  8.000000       NaN  8.0  8.00  8.0  8.00  8.0\n",
      " Electronic          1.0  7.000000       NaN  7.0  7.00  7.0  7.00  7.0\n",
      " Dance               1.0  9.000000       NaN  9.0  9.00  9.0  9.00  9.0\n",
      "Pop Folk             1.0  7.000000       NaN  7.0  7.00  7.0  7.00  7.0\n",
      "\n",
      "Sort by Tertiary Genre\n",
      "                   count  mean       std  min  25%  50%  75%  max\n",
      "TertiaryGenre                                                    \n",
      " Synthpop            2.0   8.0  1.414214  7.0  7.5  8.0  8.5  9.0\n",
      " Alternative Rock    1.0   4.0       NaN  4.0  4.0  4.0  4.0  4.0\n",
      " Hip Hop             1.0   4.0       NaN  4.0  4.0  4.0  4.0  4.0\n",
      " Jazz                1.0   9.0       NaN  9.0  9.0  9.0  9.0  9.0\n",
      " Pop Rock            1.0   6.0       NaN  6.0  6.0  6.0  6.0  6.0\n",
      "Hip Hop              1.0   5.0       NaN  5.0  5.0  5.0  5.0  5.0\n",
      "\n",
      "Sort by Country of Origin\n",
      "              count      mean       std  min  25%  50%   75%  max\n",
      "Origin                                                           \n",
      "US             43.0  5.674419  1.755548  0.0  4.5  6.0  7.00  9.0\n",
      "UK             16.0  5.812500  1.641899  4.0  4.0  6.0  6.25  9.0\n",
      "Japan           2.0  5.000000  0.000000  5.0  5.0  5.0  5.00  5.0\n",
      "Nigeria         1.0  5.000000       NaN  5.0  5.0  5.0  5.00  5.0\n",
      "Turkey          1.0  6.000000       NaN  6.0  6.0  6.0  6.00  6.0\n",
      "South Africa    1.0  9.000000       NaN  9.0  9.0  9.0  9.00  9.0\n",
      "Serbia          1.0  3.000000       NaN  3.0  3.0  3.0  3.00  3.0\n",
      "Russia          1.0  6.000000       NaN  6.0  6.0  6.0  6.00  6.0\n",
      "Romania         1.0  5.000000       NaN  5.0  5.0  5.0  5.00  5.0\n",
      "Poland          1.0  4.000000       NaN  4.0  4.0  4.0  4.00  4.0\n",
      "Norway          1.0  6.000000       NaN  6.0  6.0  6.0  6.00  6.0\n",
      "Albania         1.0  6.000000       NaN  6.0  6.0  6.0  6.00  6.0\n",
      "Brazil          1.0  7.000000       NaN  7.0  7.0  7.0  7.00  7.0\n",
      "Ireland         1.0  7.000000       NaN  7.0  7.0  7.0  7.00  7.0\n",
      "Indonesia       1.0  3.000000       NaN  3.0  3.0  3.0  3.00  3.0\n",
      "India           1.0  5.000000       NaN  5.0  5.0  5.0  5.00  5.0\n",
      "France          1.0  5.000000       NaN  5.0  5.0  5.0  5.00  5.0\n",
      "Finland         1.0  5.000000       NaN  5.0  5.0  5.0  5.00  5.0\n",
      "Cuba            1.0  6.000000       NaN  6.0  6.0  6.0  6.00  6.0\n",
      "Chlie           1.0  9.000000       NaN  9.0  9.0  9.0  9.00  9.0\n",
      "Canada          1.0  7.000000       NaN  7.0  7.0  7.0  7.00  7.0\n",
      "Korea           1.0  5.000000       NaN  5.0  5.0  5.0  5.00  5.0\n",
      "\n",
      "Sort by Year\n",
      "      count      mean       std  min  25%  50%  75%  max\n",
      "Year                                                    \n",
      "2017   77.0  5.675325  1.641898  0.0  5.0  6.0  7.0  9.0\n",
      "2016    3.0  6.333333  2.516611  4.0  5.0  6.0  7.5  9.0\n"
     ]
    }
   ],
   "source": [
    "a=data['Score'].groupby(data['PrimaryGenre']).describe()\n",
    "b=data['Score'].groupby(data['SecondaryGenre']).describe()\n",
    "c=data['Score'].groupby(data['TertiaryGenre']).describe()\n",
    "d=data['Score'].groupby(data['Origin']).describe()\n",
    "e=data['Score'].groupby(data['Year']).describe()\n",
    "\n",
    "print \"Sort by Primary Genre\"\n",
    "print a.sort_values(by='count', ascending=False)\n",
    "print \n",
    "\n",
    "print 'Sort by Secondary Genre'\n",
    "print b.sort_values(by='count', ascending=False)\n",
    "print \n",
    "\n",
    "print 'Sort by Tertiary Genre'\n",
    "print c.sort_values(by='count', ascending=False)\n",
    "print \n",
    "\n",
    "print 'Sort by Country of Origin'\n",
    "print d.sort_values(by='count', ascending=False)\n",
    "print \n",
    "\n",
    "print \"Sort by Year\"\n",
    "print e.sort_values(by='count', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "artists=data.Artist.unique()\n",
    "country=data.Origin.unique()\n",
    "genre1=data.PrimaryGenre.unique()\n",
    "genre2=data.SecondaryGenre.unique()\n",
    "genre3=data.TertiaryGenre.unique()\n",
    "\n",
    "le.fit(artists)\n",
    "data['ArtistCode']=le.transform(data.Artist)\n",
    "\n",
    "le.fit(country)\n",
    "data['CountryCode']=le.transform(data.Origin)\n",
    "\n",
    "le.fit(genre1)\n",
    "data['Genre1Code']=le.transform(data.PrimaryGenre)\n",
    "\n",
    "le.fit(genre2)\n",
    "data['Genre2Code']=le.transform(data.SecondaryGenre)\n",
    "\n",
    "le.fit(genre3)\n",
    "data['Genre3Code']=le.transform(data.TertiaryGenre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "LinReg = LinearRegression()\n",
    "BayesRidge = linear_model.BayesianRidge()\n",
    "Ridge = linear_model.Ridge(alpha=1.0)\n",
    "\n",
    "\n",
    "\n",
    "accLinReg = []\n",
    "for i in range(500): \n",
    "    msk = np.random.rand(len(data)) <= 0.79\n",
    "    train = data[msk]\n",
    "    test = data[~msk]\n",
    "    x_train=train.iloc[:,range(8,14)]\n",
    "    y_train= train.iloc[:,0].values\n",
    "    x_test=test.iloc[:,range(8,14)]\n",
    "    y_test= test.iloc[:,0].values\n",
    "    LinReg.fit(x_train, y_train)\n",
    "    y_pred_lin = LinReg.predict(x_test)\n",
    "    y_pred_lin=np.rint(y_pred_lin)\n",
    "    accLinReg.append(accuracy_score(y_test, y_pred_lin))\n",
    "    \n",
    "    \n",
    "# accBr = []\n",
    "# for i in range(500): \n",
    "#     msk = np.random.rand(len(data)) <= 0.79\n",
    "#     train = data[msk]\n",
    "#     test = data[~msk]\n",
    "#     x_train=train.iloc[:,range(8,14)]\n",
    "#     y_train= train.iloc[:,0].values\n",
    "#     x_test=test.iloc[:,range(8,14)]\n",
    "#     y_test= test.iloc[:,0].values\n",
    "#     BayesRidge.fit(x_train, y_train)\n",
    "#     y_pred_br = BayesRidge.predict(x_test)\n",
    "#     y_pred_br=np.rint(y_pred_br)\n",
    "#     accBr.append(accuracy_score(y_test, y_pred_br))\n",
    "    \n",
    "    \n",
    "accR = []\n",
    "for i in range(500): \n",
    "    msk = np.random.rand(len(data)) <= 0.79\n",
    "    train = data[msk]\n",
    "    test = data[~msk]\n",
    "    x_train=train.iloc[:,range(8,14)]\n",
    "    y_train= train.iloc[:,0].values\n",
    "    x_test=test.iloc[:,range(8,14)]\n",
    "    y_test= test.iloc[:,0].values\n",
    "    Ridge.fit(x_train, y_train) \n",
    "    y_pred_r = Ridge.predict(x_test)\n",
    "    y_pred_r=np.rint(y_pred_r)\n",
    "    accR.append(accuracy_score(y_test, y_pred_r))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB, GaussianNB\n",
    "bernoulli = BernoulliNB()\n",
    "gaussian = GaussianNB()\n",
    "\n",
    "accBernoulli = []\n",
    "for i in range(500): \n",
    "    msk = np.random.rand(len(data)) <= 0.79\n",
    "    train = data[msk]\n",
    "    test = data[~msk]\n",
    "    x_train=train.iloc[:,range(8,14)]\n",
    "    y_train= train.iloc[:,0].values\n",
    "    x_test=test.iloc[:,range(8,14)]\n",
    "    y_test= test.iloc[:,0].values\n",
    "    bernoulli.fit(x_train, y_train)\n",
    "    y_pred_bernoulli=bernoulli.predict(x_test)\n",
    "    y_pred_bernoulli=np.rint(y_pred_bernoulli)\n",
    "    accBernoulli.append(accuracy_score(y_test, y_pred_bernoulli))\n",
    "\n",
    "\n",
    "accGaussian = []\n",
    "for i in range(500): \n",
    "    msk = np.random.rand(len(data)) <= 0.79\n",
    "    train = data[msk]\n",
    "    test = data[~msk]\n",
    "    x_train=train.iloc[:,range(8,14)]\n",
    "    y_train= train.iloc[:,0].values\n",
    "    x_test=test.iloc[:,range(8,14)]\n",
    "    y_test= test.iloc[:,0].values\n",
    "    gaussian.fit(x_train, y_train)\n",
    "    y_pred_gaussian=gaussian.predict(x_test)\n",
    "    y_pred_gaussian=np.rint(y_pred_gaussian)\n",
    "    accGaussian.append(accuracy_score(y_test, y_pred_gaussian))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "neigh = KNeighborsClassifier(n_neighbors=11)\n",
    "\n",
    "accKnn = []\n",
    "for i in range(500): \n",
    "    msk = np.random.rand(len(data)) <= 0.79\n",
    "    train = data[msk]\n",
    "    test = data[~msk]\n",
    "    x_train=train.iloc[:,range(8,14)]\n",
    "    y_train= train.iloc[:,0].values\n",
    "    x_test=test.iloc[:,range(8,14)]\n",
    "    y_test= test.iloc[:,0].values\n",
    "    neigh.fit(x_train, y_train)\n",
    "    y_pred_knn=neigh.predict(x_test)\n",
    "    y_pred_knn=np.rint(y_pred_knn)\n",
    "    accKnn.append(accuracy_score(y_test, y_pred_knn))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "dtree = DecisionTreeClassifier(random_state=0)\n",
    "forest = ExtraTreesClassifier(random_state=0)\n",
    "\n",
    "accDTree = []\n",
    "for i in range(500): \n",
    "    msk = np.random.rand(len(data)) <= 0.79\n",
    "    train = data[msk]\n",
    "    test = data[~msk]\n",
    "    x_train=train.iloc[:,range(8,14)]\n",
    "    y_train= train.iloc[:,0].values\n",
    "    x_test=test.iloc[:,range(8,14)]\n",
    "    y_test= test.iloc[:,0].values\n",
    "    dtree.fit(x_train, y_train)\n",
    "    y_pred_dtree=dtree.predict(x_test)\n",
    "    y_pred_dtree=np.rint(y_pred_dtree)\n",
    "    accDTree.append(accuracy_score(y_test, y_pred_dtree))\n",
    "    \n",
    "\n",
    "accForest = []\n",
    "for i in range(500): \n",
    "    msk = np.random.rand(len(data)) <= 0.79\n",
    "    train = data[msk]\n",
    "    test = data[~msk]\n",
    "    x_train=train.iloc[:,range(8,14)]\n",
    "    y_train= train.iloc[:,0].values\n",
    "    x_test=test.iloc[:,range(8,14)]\n",
    "    y_test= test.iloc[:,0].values\n",
    "    forest.fit(x_train, y_train)\n",
    "    y_pred_forest=forest.predict(x_test)\n",
    "    y_pred_forest=np.rint(y_pred_forest)\n",
    "    accForest.append(accuracy_score(y_test, y_pred_forest))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score, Linear Regression = 0.177973949349\n",
      "Accuracy Score, Ridge = 0.181607609154\n",
      "\n",
      "Accuracy Score, Gaussian NB = 0.100661956069\n",
      "Accuracy Score, Bernoulli NB = 0.154867937116\n",
      "\n",
      "Accuracy Score, kNN = 0.166120899188\n",
      "\n",
      "Accuracy Score, Decision Trees = 0.170435905849\n",
      "Accuracy Score, Extra Trees = 0.187097315082\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print 'Accuracy Score, Linear Regression = '+ str(sum(accLinReg)/500)\n",
    "#print 'Accuracy Score, Bayesian Ridge = '+ str(sum(accBr)/500)\n",
    "print 'Accuracy Score, Ridge = '+ str(sum(accR)/500)\n",
    "print \n",
    "print 'Accuracy Score, Gaussian NB = '+ str(sum(accGaussian)/500)\n",
    "print 'Accuracy Score, Bernoulli NB = '+ str(sum(accBernoulli)/500)\n",
    "print \n",
    "print 'Accuracy Score, kNN = '+ str(sum(accKnn)/500)\n",
    "print  \n",
    "print 'Accuracy Score, Decision Trees = '+ str(sum(accDTree)/500)\n",
    "print 'Accuracy Score, Extra Trees = '+ str(sum(accForest)/500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
